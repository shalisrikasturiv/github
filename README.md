**Mini Project 1** : 
**Census Data Standardization and Analysis Pipeline** - This is the project folder inside which the code and the related files are present.


***Code***
This folder contains:
1. The python code ***"census.py"*** which will perform the Data cleaning, Uploading the data to MongoDB, loading to MySQL from MongoDB.
2. The ***"census_2011.csv"*** input file for which the data cleaning and loaded the data needs to be done.
3. The ***"Telangana.txt"*** file which has the district names in Telangana State.
4. The ***"Leh(Ladakh).txt"*** file which has the district names in Jammu and Kashmir State.
5. The ***"streamlit_census.py"*** file which has the SQL queries for the scenarios which will show the output in streamlit.

***Validation Files***
This Folder contains:
1. The ***"Before Cleaning Percentage.csv"*** file which will have the percentage of na values before cleaning the census data.
2. The ***"After Cleaning Percentage.csv"*** file which will have the percentage of na values after cleaning the census data.
2. The ***"Before and After Comparison.csv"*** file which will have the percentage of na values before and after cleaning the census data.

***Presentation***
This Folder contains:
1. The ***"Shalisri Kasturi V - Census Data Standardization and Analysis Pipeline (DE-WE-E-B2).pptx"*** presentation for the project.



**Mini Project 2** : 
**A Comprehensive ETL Workflow with Python for Data Engineers** - This is the project folder inside which the code and the related files are present.

***code***
This folder contains:
1. The python code ***"code.py"*** which will perform the ETL process.
2. The log file ***"log_file.txt"*** which has all the log info, phase start time, end time and execution time of the ETL execution.
3. The transformed file ***"transformed_data.csv"*** after performing the ETL process.

***source files***
This folder contains:
All the source csv, json and xml files required for the ETL process.

***Presentation***
This Folder contains:
1. The ***"Shalisri Kasturi V - A Comprehensive ETL Workflow with Python for Data Engineers (DE-WE-E-B2).pptx"*** presentation for the project.



**Mini Project 3** : 
**Enhanced ETL Workflow with Python, AWS S3, RDS, and Glue for Data Engineers** - This is the project folder inside which the code and the related files are present.

***code***
This folder contains:
1. The python code ***"code.py"*** which will create the S3 bucket, upload files to S3 bucket, download them, perform the ETL process, upload the transformed file to S3 bucket and data to RDS.

***logfiles***
This folder contains:
The log file capturing all the events happening in the process of ETL.

***sourcefiles***
This folder contains:
All the source csv, json and xml files required for the ETL process.

***processfiles***
This folder contains:
The csv, json and xml files which were downloaded from S3 bucket to perform the ETL process.

***transformfiles***
This folder contains:
The transformed file ***"transformed_data.csv"*** after performing the ETL process.

***Presentation***
This Folder contains:
1. The ***"Shalisri Kasturi V - Enhanced ETL Workflow with Python AWS (DE-WE-E-B2).pptx"*** presentation for the project.




**Mini Project 4** : 
**ServerLogDataExtraction** - This is the project folder inside which the code and the related files are present.

***code***
This folder contains:
1. The python code ***"code.py"*** which will fetch data from a server log file, extract all email addresses along with their corresponding dates, and upload this data into a user history database.

***sourcefile***
This folder contains:
The source file mbox.txt from which the user log data is to be extracted.


***Presentation***
This Folder contains:
1. The ***"Shalisri Kasturi V - Server Log Data Extraction (DE-WE-E-B2).pptx"*** presentation for the project.